The sentiment analysis framework used in our study incorporates existing models such as BERT Transformers, Distil BERT, XLNET, LaBSE, and Roberta, among others. The experimental results demonstrate the outstanding performance of BERT base uncased sentence reranking in conjunction with Class Balancing Loss (CBL). During the training stage, the F1 scores achieved were 0.61 for Tamil and 0.59 for Tulu. In the testing phase, the F1 scores were 0.21 for Tamil and 0.56 for Tulu.
